# Motion Capture, Unity & SuperCollider

> [!TIP]
>  ğŸ¶ Hier kann man es sehen: Logic & SuperCollider
<br> <br>

Im Rahmen des Projekts wird in SuperCollider eine algorithmisierte Melodie erzeugt, bei der TonhÃ¶he und Rhythmus festgelegt werden. 
<br> <br>
<p align="center">
<em>  Klick auf das Bild, um das Video zu schauenğŸ‘‡</em>
  <p align="center">
<a href="https://www.youtube.com/watch?v=OYplfKiy_DQ">
  <img width="700"  alt="Sky" src="https://github.com/user-attachments/assets/5d08ff52-b749-42ef-bfcf-54b6007a6004" />
 <br>
</a>
 <em> Klick auf das Bild, um das Video zu schauenâ˜ï¸</em>
</p>
<br> <br>
 
Dies ist ein Musik-Runner-Spiel, entwickelt im Rahmen meiner Erfahrungen mit Motion Capture / [Qualisys-Unity-SDK](https://github.com/qualisys/QTM-Connect-For-Unity), Unity 3D und SuperCollider. 

Der Spieler steuert das Spiel, indem er den Marker bewegt. Die Bewegungsdaten werden in Unity Ã¼ber Motion Capture erfasst. Der Spieler spielt somit in Echtzeit.

<p align="center">
<img width="500" alt="3" src="https://github.com/MilaGrishkova/Sky/raw/main/Sky.jpg" />
<br>
  <em>03 Sky</em>
</p>

So funktioniert es: Die Daten (Marker-Positionen) werden von Unity an SuperCollider gesendet. Diese Daten erzeugen die TonhÃ¶he einer klingenden Note (Frequenz). In SuperCollider wird der Klang dann mithilfe der Programmiersprache synthetisiert.
Damit ist das Spiel nicht nur ein Runner, sondern auch ein Echtzeit-Musikinstrument, das sich klanglich Ã¤hnlich wie ein Theremin verhalten kann.


[Hier](https://github.com/MilaGrishkova/Portfolio/blob/main/ğŸ“Unterrichtsmaterialien/ğŸ’»SuperColliderII/05/UnityCode) kann man den Code sehen.



<a href="https://github.com/MilaGrishkova/Portfolio/tree/main/ğŸ“Unterrichtsmaterialien/ğŸ’»SuperColliderII">
  <img src="https://github.com/user-attachments/assets/988bc5f1-81e9-4eb5-86b3-a12c67cee97b" alt="back-button-icon" width="70">
</a>
